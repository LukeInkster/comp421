{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third COMP421 Assignment\n",
    "\n",
    "Suggestion: just edit and add cells to this, and submit a notebook? Give it a name that _starts with your name_, such as Frean_ThirdAssignment.ipynb\n",
    "\n",
    "Please submit using the usual ECS [submission system](https://apps.ecs.vuw.ac.nz/submit/COMP421).\n",
    "\n",
    "The nominal due date for this will be Monday 3rd Oct (I will change the submission system to reflect this shortly). Talk to Marcus if you need more time: I'm happy to allow it but want to avoid letting this assignment detract from work on, say, your 489 project writing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A: Ockham's razor\n",
    "\n",
    "\"Underfitting\" and \"overfitting\" are examples of the problems associated with complexity control in learning systems. The principle known as Ockham's razor loosely suggests that we should use the simplest model capable of accounting for the data.\n",
    "\n",
    "[Wikipedia](https://en.wikipedia.org/wiki/Occam's_razor):\n",
    "\"The probabilistic (Bayesian) basis for Occam's razor is elaborated by David J. C. MacKay in chapter 28 of his book (Information Theory, Inference, and Learning Algorithms), where he emphasises that a prior bias in favour of simpler models is not required.\"\n",
    "This claim seems to fly in the face of the whole notion of \"regularisation\", don't you think?\n",
    "\n",
    "So read [_MacKay_ Chapter 28](http://www.inference.phy.cam.ac.uk/mackay/itprnn/ps/343.355.pdf) before answering this question. (The [whole book](http://www.inference.phy.cam.ac.uk/itprnn/book.html) makes great holiday reading in fact).\n",
    "\n",
    "In your own words, explain how it is that the posterior probability of a model can be said to _automatically_ embody Ockham's principle, provided that we are able to integrate over the unknown parameters in that model.  (approx half a page?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B: structure in time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the simple HMM with start and end states shown, in which the black squares refer to factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"HMM.png\" width=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Could any of the three graphical models shown below be used to model _the same joint distribution_ as the one defined by the above graph? Explain your answer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./HMMs.png\" width=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-learning\n",
    "Take a look at my [the Q-learner notebook](Q-learner.ipynb). I think something's wrong: with a big penalty for \"falling off the cliff\", and a high probability of accidentally doing so ($\\epsilon$), it seems odd that the agent learns to cliff-walk along the edge.\n",
    "\n",
    "Find the error if you can, or tell me why you think there's no error!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
