# Assignments

## Assignment 1
Note: Some of the maths in the Assignment 1 notebook does not seem to render very well in github (e.g. vertical lines and unintended line-breaks).
But it should look okay if you pull it and run as a notebook - another advantage of doing so is that you can write  your answers into the same structure and submit that...
Marcus



## Assignment 2
The [Second assignment](SecondAssignment.ipynb) is out. The due date is September the 12th, which is the "second Monday back" (but think about submitting it early for kicks, in order to move to other things?).

## Assignment 3
Will be about something.

## Project
There is a 20% project aspect to this course, and a shortish "interview" to go with it. 

At this point the report doesn't have a particular deadline other than the end of the examination period - but we should endeavour to get it in with enough time for me to read it before we meet. However this can all still happen in the "examination period", and the timing can be made friendly to your other time constraints on a per-student basis. Note on scope: this project needs to be such that basic results / insight is easily achievable in the time of a 20 percent assessment item in a 15 point course! How many hours is that? Don't let it make a hole in the vastly more significant project of 489, for example. 

Best projects will:
   * start with an idea from a paper (or similar)
   * preferably: include your own work, e.g. use existing implementation on some new source of data
   * ALT: a pure review is possible (ie. no implementation), but must be pulling together at least 3 significantly different papers if so.


Some possible project topics might be:
   * deep Q learning, e.g. try out Q-learning with Q provided by a convnet being fed images.
   * deep policy gradient, eg. implement and play with something similar to Karpathy's blog post.
   * the LSTM / GRU "evolution" story
   * resnets, ladder nets
   * Word2Vec representation - what it is and how it's used. Use it for something.
   * deep art
   * deepDrumpf...
   * reproduce the [gradient-following demo](http://sebastianruder.com/optimizing-gradient-descent) but (i) include nadam and (ii) give it a range of 2D surfaces for visualisation.
   * HMMs (e.g. import some data from some series and perhaps execute/learn in Genie or other implementation)
   * Learn a mixture of X's where X is not Gaussian. Can investigate cost of gradient, but probably make use of autograd to actually get it going quickly.
   * [Human-level concept learning through probabilistic program induction](http://science.sciencemag.org/content/350/6266/1332.full?utm_source=sciencemagazine]
   * Your Suggestion Here

The project is your own but it would be good to get a "go ahead" from me (MF) in each case.

#### interview
The interview is MF's chance to discuss the report in person, as well as address the course as a whole. Format t.b.a. Time: sometime in the exam period. 
