{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  A super-simple environment for trying out Q-learning\n",
    "Marcus Frean\n",
    "\n",
    "Reads in a grid-world (eg. Cliff.txt). Integers in this file denote\n",
    "different types of site, which incur different rewards and successor\n",
    "states. See below for what these 'Codes' mean.\n",
    "\n",
    "Possible actions are north (0), south (1), east (2), and west (3).\n",
    "\n",
    "The Q-learning algorithm is used to adapt Q-values, which start off\n",
    "random and small.  After learning, the best policy based on the\n",
    "learned Q-values is shown in white."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import numpy as np\n",
    "import numpy.random as rng\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm  # for the colormap\n",
    "matplotlib.rcParams['figure.figsize'] = (20.0, 10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def doOneStep(r,c,Q):\n",
    "\n",
    "    # Epsilon-greedy policy:\n",
    "    if rng.random() > EPSILON: # be greedy w.r.t. current Q values\n",
    "        localQs = Q[r,c,:]\n",
    "        action = np.argmax(localQs)\n",
    "        #print('yes ')\n",
    "    else:   # this is the random exploration hack.\n",
    "        #print('heck')\n",
    "        action = rng.randint(4)   \n",
    "\n",
    "    if action==0: new_r,new_c = r-1,c # north\n",
    "    if action==1: new_r,new_c = r+1,c # south\n",
    "    if action==2: new_r,new_c = r,c+1 # east\n",
    "    if action==3: new_r,new_c = r,c-1 # west\n",
    "\n",
    "    # If you arrive in a GOAL state, update Q[r,c] towards 0.\n",
    "    if world[new_r,new_c] == GOAL:\n",
    "        change = (0.0 + 0.0  - Q[r,c,action])\n",
    "    # If arrive in a RESTART state, it's supposed to hurt...\n",
    "    # and there is no successor state to account for this episode\n",
    "    elif world[new_r,new_c] == RESTART:\n",
    "        reward = -100.0\n",
    "        change = (reward + 0.0 - Q[r,c,action])\n",
    "    # If about to hit a WALL site, set (new_r,new_c)=(r,c), update Q.\n",
    "    elif world[new_r,new_c] == WALL:\n",
    "        new_r,new_c = r,c # you can't go through the wall...\n",
    "        reward = -2.0     # ..and it hurt to hit it.\n",
    "        best_action = np.argmax(Q[new_r,new_c,:]) \n",
    "        change = (reward + GAMMA*Q[new_r,new_c,best_action] - Q[r,c,action])\n",
    "    else:\n",
    "        reward = -1.0\n",
    "        best_action = np.argmax(Q[new_r,new_c,:]) \n",
    "        # nb. this is the greedy action: this is Q-learning, not SARSA\n",
    "        change = (reward + GAMMA*Q[new_r,new_c,best_action] - Q[r,c,action])\n",
    "\n",
    "    # update Q of the previous state-action pair.\n",
    "    Q[r,c,action] = Q[r,c,action] + LEARNINGRATE*change\n",
    "    return new_r,new_c,Q\n",
    "\n",
    "\n",
    "def doOneEpisode(Q):\n",
    "    # choose randomly from the available starting positions\n",
    "    whichStart = rng.randint(len(start_positions))\n",
    "    r,c = start_positions[whichStart,0],start_positions[whichStart,1]\n",
    "    while world[r,c] in (START,VACANT):\n",
    "        r,c,Q = doOneStep(r,c,Q)\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LEARNINGRATE = 0.2 \n",
    "GAMMA = 0.9        # the discount rate.\n",
    "EPSILON = 0.2      # prob of a totally random action. Nuts!\n",
    "\n",
    "# Codes: the different types of site in the grid-world.\n",
    "WALL = 0    # impenetrable, hurts a bit\n",
    "RESTART = 1 # an early, painful, exit\n",
    "VACANT = 2  # small negative reinforcement\n",
    "START = 3   # same as VACANT, and used to start runs\n",
    "GOAL = 4    # exits without reinforcement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 3 2 1 1 1 1 1 1 1 1 1 1 2 4 0]\n",
      " [0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0]\n",
      " [0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0]\n",
      " [0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0]\n",
      " [0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0]\n",
      " [0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "world = np.genfromtxt('Cliff.txt',int)  # try 'Corner.txt' too...\n",
    "print(world)\n",
    "start_positions = np.transpose(np.where(world == 3))\n",
    "\n",
    "numrows, numcols, numacts = world.shape[0], world.shape[1], 4\n",
    "\n",
    "Q = 0.01*rng.random((numrows, numcols, numacts))\n",
    "max_row = numrows-1\n",
    "max_col = numcols-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The codes have these meanings:\n",
    "\n",
    "| # | behaviour and reward | colour |\n",
    "|------|------| ------|\n",
    "| 0 | wall (impenetrable) and -2 | BLACK |\n",
    "| 1 | restart and -100 | GREEN |\n",
    "| 2 | vacant/available site, with -1 reward | BROWN |\n",
    "| 3 | ditto (and is a start state) | PURPLE |\n",
    "| 4 | goal state (exit with reward 0) | WHITE |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n"
     ]
    }
   ],
   "source": [
    "# do some learning\n",
    "for i in range(10000):\n",
    "    if (i%1000==0): print (i)\n",
    "    Q = doOneEpisode(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiIAAAEfCAYAAAB8uK3EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4157cb2b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the world\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(211)\n",
    "ax.imshow(world, cmap=cm.cubehelix, interpolation='nearest')\n",
    "\n",
    "# Show the policy that's greedy w.r.t. Q now\n",
    "policy = np.argmax(Q,2)\n",
    "markers = ['^','v','>','<']\n",
    "xoff = 0.3*np.array([0,0,1,-1])\n",
    "yoff = 0.3*np.array([-1,1,0,0])\n",
    "for r in range(numrows):\n",
    "    for c in range(numcols):\n",
    "        if world[r,c] not in (RESTART,WALL,GOAL):\n",
    "            i = policy[r,c]\n",
    "            plt.plot([c,c+xoff[i]],[r,r+yoff[i]],'-w') # to make an arrow...!\n",
    "            plt.plot([c+xoff[i]],[r+yoff[i]],marker=markers[i],\n",
    "                     markerfacecolor='w',markeredgecolor='w',markersize=4)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
