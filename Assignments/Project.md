#DRAFT DRAFT DRAFT

## Best projects will:
   * start with an idea from a paper (or similar)
   * preferred: include your own work, e.g. use existing implementation on some new source of data
   * ALT: a review is possible (ie. implementation), but must be talking about at least 3 different papers if so.

* However this isn't a 489 project.... needs to be such that basic results / insight is easily achievable in the time of a 20 percent assessment item in a 15 point course!*

## Possible project topics?
   * deep Q learning, e.g. try out Q-learning with Q provided by a convnet being fed images.
   * deep policy gradient, eg. implement and play with something similar to Karpathy's blog post.
   * the LSTM / GRU "evolution" story
   * resnets, ladder nets
   * Word2Vec representation - what it is and how it's used. Use it for something.
   * deep art
   * deepDrumpf...
   * reproduce the [gradient-following demo](http://sebastianruder.com/optimizing-gradient-descent) but (i) include nadam and (ii) give it a range of 2D surfaces for visualisation.
   * HMMs (e.g. import some data from some series and perhaps execute/learn in Genie or other implementation)
   * Learn a mixture of X's where X is not Gaussian. Can investigate cost of gradient, but probably make use of autograd to actually get it going quickly.
   * [Human-level concept learning through probabilistic program induction](http://science.sciencemag.org/content/350/6266/1332.full?utm_source=sciencemagazine]
