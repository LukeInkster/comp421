#DRAFT DRAFT DRAFT

There is a 20% project aspect to this course, and a shortish "interview" to go with it. I am thinking of the interview as my chance to clarify any aspects of the report that I don't understand, in person.

At this stage the report doesn't have a deadline - other than the end of the examination period - but we should endeavour to get it in with enough time for me to read it before we meet. But this can all happen in the "examination period", and the timing can be made friendly to your other time constraints on a per-student basis.

This is still DRAFT, but my current thinking is:

## Best projects will:
   * start with an idea from a paper (or similar)
   * preferred: include your own work, e.g. use existing implementation on some new source of data
   * ALT: a review is possible (ie. implementation), but must be talking about at least 3 different papers if so.

* However this isn't a 489 project.... needs to be such that basic results / insight is easily achievable in the time of a 20 percent assessment item in a 15 point course!* How many hours is that?

## Some possible project topics might be.......
   * deep Q learning, e.g. try out Q-learning with Q provided by a convnet being fed images.
   * deep policy gradient, eg. implement and play with something similar to Karpathy's blog post.
   * the LSTM / GRU "evolution" story
   * resnets, ladder nets
   * Word2Vec representation - what it is and how it's used. Use it for something.
   * deep art
   * deepDrumpf...
   * reproduce the [gradient-following demo](http://sebastianruder.com/optimizing-gradient-descent) but (i) include nadam and (ii) give it a range of 2D surfaces for visualisation.
   * HMMs (e.g. import some data from some series and perhaps execute/learn in Genie or other implementation)
   * Learn a mixture of X's where X is not Gaussian. Can investigate cost of gradient, but probably make use of autograd to actually get it going quickly.
   * [Human-level concept learning through probabilistic program induction](http://science.sciencemag.org/content/350/6266/1332.full?utm_source=sciencemagazine]
