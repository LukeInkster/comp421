# Week 6 - several things this week!


## More about Reinforcement Learning
`(Tuesday: Marcus)`
* We continue with the material from last week in [RL with Values](https://github.com/garibaldu/comp421/blob/master/week5/lecture_RL_via_Values.pdf). Note I've added a [notebook demonstration of Value Iteration](https://github.com/garibaldu/comp421/blob/master/notebooks/demo_value_iteration.ipynb) there.
* Today I hope to also make mention of RL via policy gradient [RL via policy gradient](https://github.com/garibaldu/comp421/blob/master/week6/lecture_RL_via_policy_gradient.pdf). This will have to be brief - policy gradient is worth more time, but I leave this with you to explore (e.g. in the project) if you wish.
* For those wanting more: 
   * [Scholarpedia article on policy gradient methods](http://www.scholarpedia.org/article/Policy_gradient_methods)
   * [tutorial on deep RL](https://gym.openai.com/docs/rl)

## DeepArt
`(Tuesday: led by Linfeng and Yi)`
* this is an application
* here is the [paper](https://arxiv.org/pdf/1508.06576v2.pdf)
* (MF: I found [this](https://www.robots.ox.ac.uk/~vgg/rg/slides/weidi_rg.pdf) a useful summary too, and pointed me to this earlier paper that just looks at the procedure used for making of images from representations i.e. [inversion](http://arxiv.org/pdf/1412.0035v1.pdf) )

## Q & A
`(Friday: lab / tutorial session)`
* Q and A: email me questions by noon Thursday please.
* also: autograd?


